{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22f5114-3dcd-4ed6-8885-fa7b50aa4857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for 'illed':\n",
      "illed\n",
      "0    57684\n",
      "1       22\n",
      "Name: count, dtype: int64\n",
      "Class distribution for 'injured':\n",
      "injured\n",
      "0    57529\n",
      "1      177\n",
      "Name: count, dtype: int64\n",
      "Training Random Forest - Injured...\n",
      "Training Logistic Regression - Injured...\n",
      "Training XGBoost - Injured...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingyangzuo/miniconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [10:57:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest - Ill...\n",
      "Training Logistic Regression - Ill...\n",
      "Training XGBoost - Ill...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingyangzuo/miniconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [10:58:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Predictions for Injured...\n",
      "Making Predictions for Ill...\n",
      "Calculating Accuracy for Models...\n",
      "Making Predictions for Real-Use Data...\n",
      "Predictions, evaluation results, and confusion matrices saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl import Workbook\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------\n",
    "## Step 1: Model Initializing\n",
    "\n",
    "# load training and testing data\n",
    "train_df = pd.read_excel(\"cleaned_training_data_v3.xlsx\")\n",
    "test_df = pd.read_excel(\"cleaned_test_data_v3.xlsx\")\n",
    "real_df = pd.read_excel(\"cleaned_realuse_data_v3.xlsx\")\n",
    "\n",
    "# features for prediction\n",
    "features = [\n",
    "    'sleep_score', \n",
    "    'weekly_training_load', 'weekly_training_duration', 'RTT', 'Mood state', 'Muscle readiness', 'Energy levels', 'Academic Pressure'\n",
    "]\n",
    "\n",
    "# targets\n",
    "targets = ['illed', 'injured']\n",
    "\n",
    "# keep User ID, Name, and Date for reference\n",
    "user_info_columns = ['User ID', 'Date']\n",
    "\n",
    "# drop missing values in features or targets\n",
    "train_df = train_df.dropna(subset=features + targets)\n",
    "test_df = test_df.dropna(subset=features + targets)\n",
    "\n",
    "# define X (features) and Y (targets)\n",
    "X_train = train_df[features]\n",
    "y_train_ill = train_df['illed']\n",
    "y_train_injured = train_df['injured']\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test_ill = test_df['illed']\n",
    "y_test_injured = test_df['injured']\n",
    "\n",
    "# standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------\n",
    "## Step 2: Handle Class Imbalance\n",
    "\n",
    "# check class distribution\n",
    "print(\"Class distribution for 'illed':\")\n",
    "print(y_train_ill.value_counts())\n",
    "\n",
    "print(\"Class distribution for 'injured':\")\n",
    "print(y_train_injured.value_counts())\n",
    "\n",
    "# method 1: resampling (SMOTE for oversampling)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_injured, y_train_resampled_injured = smote.fit_resample(X_train_scaled, y_train_injured)\n",
    "X_train_resampled_ill, y_train_resampled_ill = smote.fit_resample(X_train_scaled, y_train_ill)\n",
    "\n",
    "# method 2: Adjust class weights\n",
    "class_weights_injured = {\n",
    "    0: len(y_train_injured) / (2 * len(y_train_injured[y_train_injured == 0])),\n",
    "    1: len(y_train_injured) / (2 * len(y_train_injured[y_train_injured == 1]))\n",
    "}\n",
    "\n",
    "class_weights_ill = {\n",
    "    0: len(y_train_ill) / (2 * len(y_train_ill[y_train_ill == 0])),\n",
    "    1: len(y_train_ill) / (2 * len(y_train_ill[y_train_ill == 1]))\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Training Random Forest - Injured...\")\n",
    "rf_model_injured = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    class_weight=class_weights_injured,  # Adjust class weights\n",
    "    random_state=42\n",
    ")\n",
    "rf_model_injured.fit(X_train_resampled_injured, y_train_resampled_injured)  # Use resampled data\n",
    "\n",
    "print(\"Training Logistic Regression - Injured...\")\n",
    "lr_model_injured = LogisticRegression(\n",
    "    C=10,  \n",
    "    max_iter=100,  \n",
    "    solver='liblinear',  \n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "lr_model_injured.fit(X_train_resampled_injured, y_train_resampled_injured)  # Use resampled data\n",
    "\n",
    "print(\"Training XGBoost - Injured...\")\n",
    "xgb_model_injured = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,  \n",
    "    n_estimators=3000, \n",
    "    max_depth=6,  \n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=len(y_train_injured[y_train_injured == 0]) / len(y_train_injured[y_train_injured == 1]),\n",
    "    gamma=0.1,  # regularization parameter to avoid overfitting\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model_injured.fit(X_train_resampled_injured, y_train_resampled_injured)  # Use resampled data\n",
    "\n",
    "print(\"Training Random Forest - Ill...\")\n",
    "rf_model_ill = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    class_weight=class_weights_ill,  # Adjust class weights\n",
    "    random_state=42\n",
    ")\n",
    "rf_model_ill.fit(X_train_resampled_ill, y_train_resampled_ill)  # Use resampled data\n",
    "\n",
    "print(\"Training Logistic Regression - Ill...\")\n",
    "lr_model_ill = LogisticRegression(\n",
    "    C=10, \n",
    "    max_iter=100, \n",
    "    solver='liblinear', \n",
    "    class_weight='balanced', \n",
    "    random_state=42\n",
    ")\n",
    "lr_model_ill.fit(X_train_resampled_ill, y_train_resampled_ill)  # Use resampled data\n",
    "\n",
    "print(\"Training XGBoost - Ill...\")\n",
    "xgb_model_ill = xgb.XGBClassifier(\n",
    "    learning_rate=0.01,  \n",
    "    n_estimators=3000,  \n",
    "    max_depth=6,  \n",
    "    subsample=0.9, \n",
    "    colsample_bytree=0.8, \n",
    "    scale_pos_weight=len(y_train_ill[y_train_ill == 0]) / len(y_train_ill[y_train_ill == 1]),\n",
    "    gamma=0.1,  # regularization parameter to avoid overfitting\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model_ill.fit(X_train_resampled_ill, y_train_resampled_ill)  # Use resampled data\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------------------\n",
    "## Step 4: Model Evaluating\n",
    "\n",
    "# predictions\n",
    "print(\"Making Predictions for Injured...\")\n",
    "y_pred_rf_injured = rf_model_injured.predict(X_test_scaled)\n",
    "y_pred_lr_injured = lr_model_injured.predict(X_test_scaled)\n",
    "y_pred_xgb_injured = xgb_model_injured.predict(X_test_scaled)\n",
    "\n",
    "print(\"Making Predictions for Ill...\")\n",
    "y_pred_rf_ill = rf_model_ill.predict(X_test_scaled)\n",
    "y_pred_lr_ill = lr_model_ill.predict(X_test_scaled)\n",
    "y_pred_xgb_ill = xgb_model_ill.predict(X_test_scaled)\n",
    "\n",
    "# calculate accuracy for each model\n",
    "print(\"Calculating Accuracy for Models...\")\n",
    "accuracy_rf_injured = accuracy_score(y_test_injured, y_pred_rf_injured)\n",
    "accuracy_lr_injured = accuracy_score(y_test_injured, y_pred_lr_injured)\n",
    "accuracy_xgb_injured = accuracy_score(y_test_injured, y_pred_xgb_injured)\n",
    "\n",
    "accuracy_rf_ill = accuracy_score(y_test_ill, y_pred_rf_ill)\n",
    "accuracy_lr_ill = accuracy_score(y_test_ill, y_pred_lr_ill)\n",
    "accuracy_xgb_ill = accuracy_score(y_test_ill, y_pred_xgb_ill)\n",
    "\n",
    "# save test set evaluation results to Excel\n",
    "test_evaluation_results = {\n",
    "    'Model': ['Random Forest', 'Logistic Regression', 'XGBoost'],\n",
    "    'Accuracy_Injured': [accuracy_rf_injured, accuracy_lr_injured, accuracy_xgb_injured],\n",
    "    'Accuracy_Ill': [accuracy_rf_ill, accuracy_lr_ill, accuracy_xgb_ill]\n",
    "}\n",
    "test_evaluation_df = pd.DataFrame(test_evaluation_results)\n",
    "\n",
    "\n",
    "# drop rows with missing values for the specific features\n",
    "real_df = real_df.dropna(subset=features)\n",
    "X_real = real_df[features]\n",
    "X_real_scaled = scaler.transform(X_real)\n",
    "\n",
    "# predict using the best model (we can choose the model we prefer from Random Forest, Logistic Regression and XGBoost)\n",
    "print(\"Making Predictions for Real-Use Data...\")\n",
    "real_df['Prediction_Injury_RandomForest'] = rf_model_injured.predict(X_real_scaled)\n",
    "real_df['Prediction_Injury_LogisticRegression'] = lr_model_injured.predict(X_real_scaled)\n",
    "real_df['Prediction_Injury_XGBoost'] = xgb_model_injured.predict(X_real_scaled)\n",
    "\n",
    "real_df['Prediction_Illness_RandomForest'] = rf_model_ill.predict(X_real_scaled)\n",
    "real_df['Prediction_Illness_LogisticRegression'] = lr_model_ill.predict(X_real_scaled)\n",
    "real_df['Prediction_Illness_XGBoost'] = xgb_model_ill.predict(X_real_scaled)\n",
    "\n",
    "# calculate correctness for each row in real-use data\n",
    "real_df['Correct_check_Injury_RandomForest'] = (real_df['Prediction_Injury_RandomForest'] == real_df['injured']).astype(int)\n",
    "real_df['Correct_check_Injury_LogisticRegression'] = (real_df['Prediction_Injury_LogisticRegression'] == real_df['injured']).astype(int)\n",
    "real_df['Correct_check_Injury_XGBoost'] = (real_df['Prediction_Injury_XGBoost'] == real_df['injured']).astype(int)\n",
    "\n",
    "real_df['Correct_check_Illness_RandomForest'] = (real_df['Prediction_Illness_RandomForest'] == real_df['illed']).astype(int)\n",
    "real_df['Correct_check_Illness_LogisticRegression'] = (real_df['Prediction_Illness_LogisticRegression'] == real_df['illed']).astype(int)\n",
    "real_df['Correct_check_Illness_XGBoost'] = (real_df['Prediction_Illness_XGBoost'] == real_df['illed']).astype(int)\n",
    "\n",
    "# calculate global accuracy for real-use data\n",
    "real_rf_injured_acc = real_df['Correct_check_Injury_RandomForest'].mean()\n",
    "real_lr_injured_acc = real_df['Correct_check_Injury_LogisticRegression'].mean()\n",
    "real_xgb_injured_acc = real_df['Correct_check_Injury_XGBoost'].mean()\n",
    "\n",
    "real_rf_ill_acc = real_df['Correct_check_Illness_RandomForest'].mean()\n",
    "real_lr_ill_acc = real_df['Correct_check_Illness_LogisticRegression'].mean()\n",
    "real_xgb_ill_acc = real_df['Correct_check_Illness_XGBoost'].mean()\n",
    "\n",
    "# add global accuracy columns to real-use data\n",
    "real_df['Total_accuracy_Injury_RandomForest'] = real_rf_injured_acc\n",
    "real_df['Total_accuracy_Injury_LogisticRegression'] = real_lr_injured_acc\n",
    "real_df['Total_accuracy_Injury_XGBoost'] = real_xgb_injured_acc\n",
    "\n",
    "real_df['Total_accuracy_Illness_RandomForest'] = real_rf_ill_acc\n",
    "real_df['Total_accuracy_Illness_LogisticRegression'] = real_lr_ill_acc\n",
    "real_df['Total_accuracy_Illness_XGBoost'] = real_xgb_ill_acc\n",
    "\n",
    "# highlight incorrect predictions in Excel\n",
    "def highlight_incorrect_predictions(df, writer, sheet_name):\n",
    "    wb = writer.book\n",
    "    ws = wb[sheet_name]\n",
    "    red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "    \n",
    "    # iterate over each row in the DataFrame\n",
    "    for row_idx in range(len(df)):  # use range(len(df)) to iterate over valid row indices\n",
    "        for col in ['Correct_check_Injury_RandomForest', 'Correct_check_Injury_LogisticRegression', 'Correct_check_Injury_XGBoost',\n",
    "                    'Correct_check_Illness_RandomForest', 'Correct_check_Illness_LogisticRegression', 'Correct_check_Illness_XGBoost']:\n",
    "            if df.iloc[row_idx][col] == 0:  # use iloc to access rows by position\n",
    "                # excel rows start from 1, and we need to skip the header row\n",
    "                ws.cell(row=row_idx + 2, column=df.columns.get_loc(col) + 1).fill = red_fill\n",
    "\n",
    "\n",
    "# generate bar chart for accuracy comparison\n",
    "models = ['Random Forest', 'Logistic Regression', 'XGBoost']\n",
    "\n",
    "# test data accuracy\n",
    "train_injury_accuracies = [accuracy_rf_injured, accuracy_lr_injured, accuracy_xgb_injured]\n",
    "train_illness_accuracies = [accuracy_rf_ill, accuracy_lr_ill, accuracy_xgb_ill]\n",
    "\n",
    "# realuse data accuracy\n",
    "test_injury_accuracies = [real_rf_injured_acc, real_lr_injured_acc, real_xgb_injured_acc]\n",
    "test_illness_accuracies = [real_rf_ill_acc, real_lr_ill_acc, real_xgb_ill_acc]\n",
    "\n",
    "# save results to Excel\n",
    "with pd.ExcelWriter('prediction_v5_no_diet_yesterday.xlsx', engine='openpyxl') as writer:\n",
    "    # Test set evaluation results\n",
    "    test_evaluation_df.to_excel(writer, sheet_name='Test_Evaluation_Accuracy', index=False)\n",
    "    \n",
    "    # real-use data\n",
    "    real_predictions = real_df[user_info_columns + [\n",
    "        'Prediction_Injury_RandomForest', 'Correct_check_Injury_RandomForest','Total_accuracy_Injury_RandomForest',\n",
    "        'Prediction_Injury_LogisticRegression', 'Correct_check_Injury_LogisticRegression','Total_accuracy_Injury_LogisticRegression',\n",
    "        'Prediction_Injury_XGBoost', 'Correct_check_Injury_XGBoost','Total_accuracy_Injury_XGBoost',\n",
    "        'Prediction_Illness_RandomForest', 'Correct_check_Illness_RandomForest','Total_accuracy_Illness_RandomForest',\n",
    "        'Prediction_Illness_LogisticRegression', 'Correct_check_Illness_LogisticRegression','Total_accuracy_Illness_LogisticRegression',\n",
    "        'Prediction_Illness_XGBoost', 'Correct_check_Illness_XGBoost','Total_accuracy_Illness_XGBoost'\n",
    "    ]]\n",
    "    real_predictions.to_excel(writer, sheet_name='Real-Use_Predictions', index=False)\n",
    "    highlight_incorrect_predictions(real_predictions, writer, 'Real-Use_Predictions')\n",
    "\n",
    "print(\"Predictions, evaluation results, and confusion matrices saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b32a1-e6de-4ea5-adf9-f4720472c935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
