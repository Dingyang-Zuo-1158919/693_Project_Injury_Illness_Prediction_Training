{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bd6365-9b6b-4566-b317-efbdeafd587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Excel report: additional_report_no_severity.xlsx\n",
      "Successfully saved report to: /Users/dingyangzuo/additional_report_no_severity.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from difflib import SequenceMatcher\n",
    "from openpyxl.styles import PatternFill, Font, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule, ColorScaleRule\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.chart import BarChart\n",
    "from openpyxl.chart.reference import Reference\n",
    "\n",
    "\n",
    "# 1. load saved models and preprocessing objects\n",
    "model_dir = 'saved_models_additional_v2'\n",
    "models = {\n",
    "    'illness': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_illness.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_illness.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_injury.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_injury.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# load vectorizers and encoders\n",
    "vectorizers = {\n",
    "    'illness': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_illness.pkl')),\n",
    "    'injury': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_injury.pkl'))\n",
    "}\n",
    "\n",
    "label_encoders = {\n",
    "    'illness': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_illness_label_encoder.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_injury_label_encoder.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. load and prepare data with column name standardization\n",
    "def load_and_prepare_data(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # standardize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # handle missing values\n",
    "    df['illness_information'] = df['illness_information'].fillna(\"No Illness\")\n",
    "    df['injury_information'] = df['injury_information'].fillna(\"No Injury\")\n",
    "    \n",
    "    # ensure required columns exist\n",
    "    if 'user_id' not in df.columns:\n",
    "        df['user_id'] = np.arange(1, len(df)+1)\n",
    "    \n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # convert date to string if it's datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "        df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "test_df = load_and_prepare_data(\"cleaned_test_data_v3.xlsx\")\n",
    "realuse_df = load_and_prepare_data(\"cleaned_realuse_data_v3.xlsx\")\n",
    "\n",
    "# 3. enhanced prediction function\n",
    "def predict_with_models(text, problem_type, actual):\n",
    "    predictions = {}\n",
    "    if text in [\"No Illness\", \"No Injury\"]:\n",
    "        return {model: (\"No Prediction\", 0) for model in models[problem_type].keys()}\n",
    "    \n",
    "    vectorized = vectorizers[problem_type].transform([text])\n",
    "    \n",
    "    for model_name, model in models[problem_type].items():\n",
    "        pred = model.predict(vectorized)[0]\n",
    "        \n",
    "        if model_name in ['Logistic Regression', 'XGBoost']:\n",
    "            pred = label_encoders[problem_type][model_name].inverse_transform([pred])[0]\n",
    "        \n",
    "        similarity = SequenceMatcher(None, str(actual), str(pred)).ratio() * 100\n",
    "        predictions[model_name] = (pred, similarity)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 4. process dataset to create flattened results - only for rows with illness or injury\n",
    "def process_dataset(df):\n",
    "    illness_results = []\n",
    "    injury_results = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        user_id = str(row['user_id'])\n",
    "        date = str(row['date'])\n",
    "        \n",
    "        # process illness if present\n",
    "        if row['illed'] == 1 and row['illness_information'] != \"No Illness\":\n",
    "            illness_actual = row['illness_information']\n",
    "            illness_preds = predict_with_models(illness_actual, 'illness', illness_actual)\n",
    "            \n",
    "            illness_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': illness_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in illness_preds.items():\n",
    "                illness_data[f\"{model_name} Predicted\"] = predicted\n",
    "                illness_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                illness_data[f\"{model_name} Correct\"] = illness_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            illness_results.append(illness_data)\n",
    "        \n",
    "        # process injury if present\n",
    "        if row['injured'] == 1 and row['injury_information'] != \"No Injury\":\n",
    "            injury_actual = row['injury_information']\n",
    "            injury_preds = predict_with_models(injury_actual, 'injury', injury_actual)\n",
    "            \n",
    "            injury_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': injury_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in injury_preds.items():\n",
    "                injury_data[f\"{model_name} Predicted\"] = predicted\n",
    "                injury_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                injury_data[f\"{model_name} Correct\"] = injury_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            injury_results.append(injury_data)\n",
    "            \n",
    "    def sort_dataframe(df):\n",
    "        if not df.empty:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.sort_values(['Date', 'User ID'])\n",
    "            df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "        return df\n",
    "    \n",
    "    return {\n",
    "        'illness': sort_dataframe(pd.DataFrame(illness_results)),\n",
    "        'injury': sort_dataframe(pd.DataFrame(injury_results))\n",
    "    }\n",
    "\n",
    "# 5. process both datasets\n",
    "test_results = {\n",
    "    'illness': process_dataset(test_df)['illness'],\n",
    "    'injury': process_dataset(test_df)['injury']\n",
    "}\n",
    "\n",
    "realuse_results = {\n",
    "    'illness': process_dataset(realuse_df)['illness'],\n",
    "    'injury': process_dataset(realuse_df)['injury']\n",
    "}\n",
    "\n",
    "# 6. create Excel report with enhanced formatting\n",
    "def create_excel_report():\n",
    "    output_file = 'additional_report_no_severity.xlsx'\n",
    "    print(f\"\\nGenerating Excel report: {output_file}\")\n",
    "    \n",
    "    # create styles\n",
    "    green_fill = PatternFill(start_color='00FF00', end_color='00FF00', fill_type='solid')\n",
    "    red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "    header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    header_font = Font(color='FFFFFF', bold=True)\n",
    "    summary_header_fill = PatternFill(start_color='7030A0', end_color='7030A0', fill_type='solid')\n",
    "    center_alignment = Alignment(horizontal='center')\n",
    "    \n",
    "    color_scale_rule = ColorScaleRule(\n",
    "        start_type='num', start_value=0, start_color='FF0000',\n",
    "        mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "        end_type='num', end_value=100, end_color='00FF00'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # create a new workbook\n",
    "        wb = openpyxl.Workbook()\n",
    "        \n",
    "        # create sheets for each dataset and problem type\n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                sheet_name = f\"{dataset_name} {problem_type.capitalize()}\"[:31]\n",
    "                ws = wb.create_sheet(sheet_name)\n",
    "                \n",
    "                # write the data to the worksheet\n",
    "                for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n",
    "                    for c_idx, value in enumerate(row, 1):\n",
    "                        ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "                \n",
    "                # apply header formatting\n",
    "                for cell in ws[1]:\n",
    "                    cell.fill = header_fill\n",
    "                    cell.font = header_font\n",
    "                    cell.alignment = center_alignment\n",
    "                \n",
    "                # find accuracy and correct columns\n",
    "                for col_idx, col in enumerate(ws.iter_cols(), 1):\n",
    "                    col_name = col[0].value\n",
    "                    \n",
    "                    if col_name and 'Accuracy (%)' in col_name:\n",
    "                        # apply color scale to accuracy columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            color_scale_rule\n",
    "                        )\n",
    "                    \n",
    "                    elif col_name and 'Correct' in col_name:\n",
    "                        # apply green/red to correctness columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['TRUE'], fill=green_fill)\n",
    "                        )\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['FALSE'], fill=red_fill)\n",
    "                        )\n",
    "                \n",
    "                # auto-size columns\n",
    "                for column in ws.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(str(cell.value))\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = (max_length + 2)\n",
    "                    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # create summary sheet\n",
    "        ws_summary = wb.create_sheet(\"Model Performance Summary\")\n",
    "        \n",
    "        # prepare summary data\n",
    "        summary_data = []\n",
    "        models_list = ['Random Forest', 'Logistic Regression', 'XGBoost']\n",
    "        \n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                for model in models_list:\n",
    "                    # calculate average accuracy\n",
    "                    acc_col = f\"{model} Accuracy (%)\"\n",
    "                    if acc_col in df.columns:\n",
    "                        avg_accuracy = df[acc_col].mean()\n",
    "                        \n",
    "                        # calculate error rate (false predictions percentage)\n",
    "                        correct_col = f\"{model} Correct\"\n",
    "                        if correct_col in df.columns:\n",
    "                            total_predictions = len(df[correct_col])\n",
    "                            true_predictions = len(df[df[correct_col] == True])\n",
    "                            accuracy_rate = (true_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "                            \n",
    "                            summary_data.append({\n",
    "                                'Dataset': dataset_name,\n",
    "                                'Problem Type': problem_type.capitalize(),\n",
    "                                'Model': model,\n",
    "                                'Average Accuracy (%)': round(avg_accuracy, 1),\n",
    "                                'Accuracy Rate (%)': round(accuracy_rate, 1),\n",
    "                                'Total Predictions': total_predictions\n",
    "                            })\n",
    "        \n",
    "        # create summary DataFrame\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # write summary to Excel\n",
    "        for r_idx, row in enumerate(dataframe_to_rows(summary_df, index=False, header=True), 1):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                ws_summary.cell(row=r_idx, column=c_idx, value=value)\n",
    "        \n",
    "        # format summary sheet\n",
    "        for cell in ws_summary[1]:\n",
    "            cell.fill = summary_header_fill\n",
    "            cell.font = header_font\n",
    "            cell.alignment = center_alignment\n",
    "        \n",
    "        # apply conditional formatting to accuracy and error rate\n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"D2:D{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000',\n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"E2:E{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000', \n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00', \n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Auto-size columns\n",
    "        for column in ws_summary.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            ws_summary.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # Add charts to summary sheet\n",
    "        chart1 = BarChart()\n",
    "        chart1.title = \"Average Accuracy by Model\"\n",
    "        chart1.y_axis.title = \"Accuracy (%)\"\n",
    "        chart1.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=4, min_row=1, max_row=ws_summary.max_row, max_col=4)\n",
    "        cats = Reference(ws_summary, min_col=3, min_row=2, max_row=ws_summary.max_row)\n",
    "        chart1.add_data(data, titles_from_data=True)\n",
    "        chart1.set_categories(cats)\n",
    "        ws_summary.add_chart(chart1, \"G2\")\n",
    "        \n",
    "        chart2 = BarChart()\n",
    "        chart2.title = \"Error Rate by Model\"\n",
    "        chart2.y_axis.title = \"Error Rate (%)\"\n",
    "        chart2.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=5, min_row=1, max_row=ws_summary.max_row, max_col=5)\n",
    "        chart2.add_data(data, titles_from_data=True)\n",
    "        chart2.set_categories(cats)\n",
    "        ws_summary.add_chart(chart2, \"G20\")\n",
    "        \n",
    "        # Remove default sheet if it exists\n",
    "        if 'Sheet' in wb.sheetnames:\n",
    "            wb.remove(wb['Sheet'])\n",
    "        \n",
    "        # Save the workbook\n",
    "        wb.save(output_file)\n",
    "        print(f\"Successfully saved report to: {os.path.abspath(output_file)}\")\n",
    "        return output_file\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Excel report: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# 7. generate the report\n",
    "report_file = create_excel_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64623a-07ea-4b60-99df-e21b8fb0d52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23de067d-a1c7-445e-a3b9-7b76e299719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Excel report: additional_report_v2.xlsx\n",
      "Successfully saved report to: /Users/dingyangzuo/additional_report_v2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from difflib import SequenceMatcher\n",
    "from openpyxl.styles import PatternFill, Font, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule, ColorScaleRule\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.chart import BarChart\n",
    "from openpyxl.chart.reference import Reference\n",
    "\n",
    "\n",
    "# 1. load saved models and preprocessing objects\n",
    "model_dir = 'saved_models_additional_training'\n",
    "models = {\n",
    "    'illness': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_illness.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_illness.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_injury.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_injury.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# load vectorizers and encoders\n",
    "vectorizers = {\n",
    "    'illness': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_illness.pkl')),\n",
    "    'injury': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_injury.pkl'))\n",
    "}\n",
    "\n",
    "label_encoders = {\n",
    "    'illness': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_illness_label_encoder.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_injury_label_encoder.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. load and prepare data with column name standardization\n",
    "def load_and_prepare_data(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # standardize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # handle missing values\n",
    "    df['illness_information'] = df['illness_information'].fillna(\"No Illness\")\n",
    "    df['injury_information'] = df['injury_information'].fillna(\"No Injury\")\n",
    "    \n",
    "    # ensure required columns exist\n",
    "    if 'user_id' not in df.columns:\n",
    "        df['user_id'] = np.arange(1, len(df)+1)\n",
    "    \n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # convert date to string if it's datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "        df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "test_df = load_and_prepare_data(\"cleaned_test_data_v3.xlsx\")\n",
    "realuse_df = load_and_prepare_data(\"cleaned_realuse_data_v3.xlsx\")\n",
    "\n",
    "# 3. enhanced prediction function\n",
    "def predict_with_models(text, problem_type, actual):\n",
    "    predictions = {}\n",
    "    if text in [\"No Illness\", \"No Injury\"]:\n",
    "        return {model: (\"No Prediction\", 0) for model in models[problem_type].keys()}\n",
    "    \n",
    "    vectorized = vectorizers[problem_type].transform([text])\n",
    "    \n",
    "    for model_name, model in models[problem_type].items():\n",
    "        pred = model.predict(vectorized)[0]\n",
    "        \n",
    "        if model_name in ['Logistic Regression', 'XGBoost']:\n",
    "            pred = label_encoders[problem_type][model_name].inverse_transform([pred])[0]\n",
    "        \n",
    "        similarity = SequenceMatcher(None, str(actual), str(pred)).ratio() * 100\n",
    "        predictions[model_name] = (pred, similarity)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 4. process dataset to create flattened results - only for rows with illness or injury\n",
    "def process_dataset(df):\n",
    "    illness_results = []\n",
    "    injury_results = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        user_id = str(row['user_id'])\n",
    "        date = str(row['date'])\n",
    "        \n",
    "        # process illness if present\n",
    "        if row['illed'] == 1 and row['illness_information'] != \"No Illness\":\n",
    "            illness_actual = row['illness_information']\n",
    "            illness_preds = predict_with_models(illness_actual, 'illness', illness_actual)\n",
    "            \n",
    "            illness_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': illness_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in illness_preds.items():\n",
    "                illness_data[f\"{model_name} Predicted\"] = predicted\n",
    "                illness_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                illness_data[f\"{model_name} Correct\"] = illness_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            illness_results.append(illness_data)\n",
    "        \n",
    "        # process injury if present\n",
    "        if row['injured'] == 1 and row['injury_information'] != \"No Injury\":\n",
    "            injury_actual = row['injury_information']\n",
    "            injury_preds = predict_with_models(injury_actual, 'injury', injury_actual)\n",
    "            \n",
    "            injury_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': injury_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in injury_preds.items():\n",
    "                injury_data[f\"{model_name} Predicted\"] = predicted\n",
    "                injury_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                injury_data[f\"{model_name} Correct\"] = injury_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            injury_results.append(injury_data)\n",
    "            \n",
    "    def sort_dataframe(df):\n",
    "        if not df.empty:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.sort_values(['Date', 'User ID'])\n",
    "            df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "        return df\n",
    "    \n",
    "    return {\n",
    "        'illness': sort_dataframe(pd.DataFrame(illness_results)),\n",
    "        'injury': sort_dataframe(pd.DataFrame(injury_results))\n",
    "    }\n",
    "\n",
    "# 5. process both datasets\n",
    "test_results = {\n",
    "    'illness': process_dataset(test_df)['illness'],\n",
    "    'injury': process_dataset(test_df)['injury']\n",
    "}\n",
    "\n",
    "realuse_results = {\n",
    "    'illness': process_dataset(realuse_df)['illness'],\n",
    "    'injury': process_dataset(realuse_df)['injury']\n",
    "}\n",
    "\n",
    "# 6. create Excel report with enhanced formatting\n",
    "def create_excel_report():\n",
    "    output_file = 'additional_report_v2.xlsx'\n",
    "    print(f\"\\nGenerating Excel report: {output_file}\")\n",
    "    \n",
    "    # create styles\n",
    "    green_fill = PatternFill(start_color='00FF00', end_color='00FF00', fill_type='solid')\n",
    "    red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "    header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    header_font = Font(color='FFFFFF', bold=True)\n",
    "    summary_header_fill = PatternFill(start_color='7030A0', end_color='7030A0', fill_type='solid')\n",
    "    center_alignment = Alignment(horizontal='center')\n",
    "    \n",
    "    color_scale_rule = ColorScaleRule(\n",
    "        start_type='num', start_value=0, start_color='FF0000',\n",
    "        mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "        end_type='num', end_value=100, end_color='00FF00'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # create a new workbook\n",
    "        wb = openpyxl.Workbook()\n",
    "        \n",
    "        # create sheets for each dataset and problem type\n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                sheet_name = f\"{dataset_name} {problem_type.capitalize()}\"[:31]\n",
    "                ws = wb.create_sheet(sheet_name)\n",
    "                \n",
    "                # write the data to the worksheet\n",
    "                for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n",
    "                    for c_idx, value in enumerate(row, 1):\n",
    "                        ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "                \n",
    "                # apply header formatting\n",
    "                for cell in ws[1]:\n",
    "                    cell.fill = header_fill\n",
    "                    cell.font = header_font\n",
    "                    cell.alignment = center_alignment\n",
    "                \n",
    "                # find accuracy and correct columns\n",
    "                for col_idx, col in enumerate(ws.iter_cols(), 1):\n",
    "                    col_name = col[0].value\n",
    "                    \n",
    "                    if col_name and 'Accuracy (%)' in col_name:\n",
    "                        # apply color scale to accuracy columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            color_scale_rule\n",
    "                        )\n",
    "                    \n",
    "                    elif col_name and 'Correct' in col_name:\n",
    "                        # apply green/red to correctness columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['TRUE'], fill=green_fill)\n",
    "                        )\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['FALSE'], fill=red_fill)\n",
    "                        )\n",
    "                \n",
    "                # auto-size columns\n",
    "                for column in ws.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(str(cell.value))\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = (max_length + 2)\n",
    "                    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # create summary sheet\n",
    "        ws_summary = wb.create_sheet(\"Model Performance Summary\")\n",
    "        \n",
    "        # prepare summary data\n",
    "        summary_data = []\n",
    "        models_list = ['Random Forest', 'Logistic Regression', 'XGBoost']\n",
    "        \n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                for model in models_list:\n",
    "                    # calculate average accuracy\n",
    "                    acc_col = f\"{model} Accuracy (%)\"\n",
    "                    if acc_col in df.columns:\n",
    "                        avg_accuracy = df[acc_col].mean()\n",
    "                        \n",
    "                        # calculate error rate (false predictions percentage)\n",
    "                        correct_col = f\"{model} Correct\"\n",
    "                        if correct_col in df.columns:\n",
    "                            total_predictions = len(df[correct_col])\n",
    "                            true_predictions = len(df[df[correct_col] == True])\n",
    "                            accuracy_rate = (true_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "                            \n",
    "                            summary_data.append({\n",
    "                                'Dataset': dataset_name,\n",
    "                                'Problem Type': problem_type.capitalize(),\n",
    "                                'Model': model,\n",
    "                                'Average Accuracy (%)': round(avg_accuracy, 1),\n",
    "                                'Accuracy Rate (%)': round(accuracy_rate, 1),\n",
    "                                'Total Predictions': total_predictions\n",
    "                            })\n",
    "        \n",
    "        # create summary DataFrame\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # write summary to Excel\n",
    "        for r_idx, row in enumerate(dataframe_to_rows(summary_df, index=False, header=True), 1):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                ws_summary.cell(row=r_idx, column=c_idx, value=value)\n",
    "        \n",
    "        # format summary sheet\n",
    "        for cell in ws_summary[1]:\n",
    "            cell.fill = summary_header_fill\n",
    "            cell.font = header_font\n",
    "            cell.alignment = center_alignment\n",
    "        \n",
    "        # apply conditional formatting to accuracy and error rate\n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"D2:D{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000',\n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"E2:E{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000', \n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00', \n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Auto-size columns\n",
    "        for column in ws_summary.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            ws_summary.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # Add charts to summary sheet\n",
    "        chart1 = BarChart()\n",
    "        chart1.title = \"Average Accuracy by Model\"\n",
    "        chart1.y_axis.title = \"Accuracy (%)\"\n",
    "        chart1.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=4, min_row=1, max_row=ws_summary.max_row, max_col=4)\n",
    "        cats = Reference(ws_summary, min_col=3, min_row=2, max_row=ws_summary.max_row)\n",
    "        chart1.add_data(data, titles_from_data=True)\n",
    "        chart1.set_categories(cats)\n",
    "        ws_summary.add_chart(chart1, \"G2\")\n",
    "        \n",
    "        chart2 = BarChart()\n",
    "        chart2.title = \"Error Rate by Model\"\n",
    "        chart2.y_axis.title = \"Error Rate (%)\"\n",
    "        chart2.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=5, min_row=1, max_row=ws_summary.max_row, max_col=5)\n",
    "        chart2.add_data(data, titles_from_data=True)\n",
    "        chart2.set_categories(cats)\n",
    "        ws_summary.add_chart(chart2, \"G20\")\n",
    "        \n",
    "        # Remove default sheet if it exists\n",
    "        if 'Sheet' in wb.sheetnames:\n",
    "            wb.remove(wb['Sheet'])\n",
    "        \n",
    "        # Save the workbook\n",
    "        wb.save(output_file)\n",
    "        print(f\"Successfully saved report to: {os.path.abspath(output_file)}\")\n",
    "        return output_file\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Excel report: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# 7. generate the report\n",
    "report_file = create_excel_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b0e8b-3e98-4e10-a002-08fc6d3d2963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e1f7b0-ea33-440d-9ade-1287117908cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Excel report: additional_report_no_severity_v2.xlsx\n",
      "Successfully saved report to: /Users/dingyangzuo/additional_report_no_severity_v2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from difflib import SequenceMatcher\n",
    "from openpyxl.styles import PatternFill, Font, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule, ColorScaleRule\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.chart import BarChart\n",
    "from openpyxl.chart.reference import Reference\n",
    "\n",
    "\n",
    "# 1. load saved models and preprocessing objects\n",
    "model_dir = 'saved_models_additional_v2_no_severity'\n",
    "models = {\n",
    "    'illness': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_illness.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_illness.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_injury.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_injury.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# load vectorizers and encoders\n",
    "vectorizers = {\n",
    "    'illness': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_illness.pkl')),\n",
    "    'injury': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_injury.pkl'))\n",
    "}\n",
    "\n",
    "label_encoders = {\n",
    "    'illness': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_illness_label_encoder.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_injury_label_encoder.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. load and prepare data with column name standardization\n",
    "def load_and_prepare_data(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # standardize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # handle missing values\n",
    "    df['illness_information'] = df['illness_information'].fillna(\"No Illness\")\n",
    "    df['injury_information'] = df['injury_information'].fillna(\"No Injury\")\n",
    "    \n",
    "    # ensure required columns exist\n",
    "    if 'user_id' not in df.columns:\n",
    "        df['user_id'] = np.arange(1, len(df)+1)\n",
    "    \n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # convert date to string if it's datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "        df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "test_df = load_and_prepare_data(\"cleaned_test_data_v3.xlsx\")\n",
    "realuse_df = load_and_prepare_data(\"cleaned_realuse_data_v3.xlsx\")\n",
    "\n",
    "# 3. enhanced prediction function\n",
    "def predict_with_models(text, problem_type, actual):\n",
    "    predictions = {}\n",
    "    if text in [\"No Illness\", \"No Injury\"]:\n",
    "        return {model: (\"No Prediction\", 0) for model in models[problem_type].keys()}\n",
    "    \n",
    "    vectorized = vectorizers[problem_type].transform([text])\n",
    "    \n",
    "    for model_name, model in models[problem_type].items():\n",
    "        pred = model.predict(vectorized)[0]\n",
    "        \n",
    "        if model_name in ['Logistic Regression', 'XGBoost']:\n",
    "            pred = label_encoders[problem_type][model_name].inverse_transform([pred])[0]\n",
    "        \n",
    "        similarity = SequenceMatcher(None, str(actual), str(pred)).ratio() * 100\n",
    "        predictions[model_name] = (pred, similarity)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 4. process dataset to create flattened results - only for rows with illness or injury\n",
    "def process_dataset(df):\n",
    "    illness_results = []\n",
    "    injury_results = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        user_id = str(row['user_id'])\n",
    "        date = str(row['date'])\n",
    "        \n",
    "        # process illness if present\n",
    "        if row['illed'] == 1 and row['illness_information'] != \"No Illness\":\n",
    "            illness_actual = row['illness_information']\n",
    "            illness_preds = predict_with_models(illness_actual, 'illness', illness_actual)\n",
    "            \n",
    "            illness_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': illness_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in illness_preds.items():\n",
    "                illness_data[f\"{model_name} Predicted\"] = predicted\n",
    "                illness_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                illness_data[f\"{model_name} Correct\"] = illness_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            illness_results.append(illness_data)\n",
    "        \n",
    "        # process injury if present\n",
    "        if row['injured'] == 1 and row['injury_information'] != \"No Injury\":\n",
    "            injury_actual = row['injury_information']\n",
    "            injury_preds = predict_with_models(injury_actual, 'injury', injury_actual)\n",
    "            \n",
    "            injury_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': injury_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in injury_preds.items():\n",
    "                injury_data[f\"{model_name} Predicted\"] = predicted\n",
    "                injury_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                injury_data[f\"{model_name} Correct\"] = injury_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            injury_results.append(injury_data)\n",
    "            \n",
    "    def sort_dataframe(df):\n",
    "        if not df.empty:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.sort_values(['Date', 'User ID'])\n",
    "            df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "        return df\n",
    "    \n",
    "    return {\n",
    "        'illness': sort_dataframe(pd.DataFrame(illness_results)),\n",
    "        'injury': sort_dataframe(pd.DataFrame(injury_results))\n",
    "    }\n",
    "\n",
    "# 5. process both datasets\n",
    "test_results = {\n",
    "    'illness': process_dataset(test_df)['illness'],\n",
    "    'injury': process_dataset(test_df)['injury']\n",
    "}\n",
    "\n",
    "realuse_results = {\n",
    "    'illness': process_dataset(realuse_df)['illness'],\n",
    "    'injury': process_dataset(realuse_df)['injury']\n",
    "}\n",
    "\n",
    "# 6. create Excel report with enhanced formatting\n",
    "def create_excel_report():\n",
    "    output_file = 'additional_report_no_severity_v2.xlsx'\n",
    "    print(f\"\\nGenerating Excel report: {output_file}\")\n",
    "    \n",
    "    # create styles\n",
    "    green_fill = PatternFill(start_color='00FF00', end_color='00FF00', fill_type='solid')\n",
    "    red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "    header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    header_font = Font(color='FFFFFF', bold=True)\n",
    "    summary_header_fill = PatternFill(start_color='7030A0', end_color='7030A0', fill_type='solid')\n",
    "    center_alignment = Alignment(horizontal='center')\n",
    "    \n",
    "    color_scale_rule = ColorScaleRule(\n",
    "        start_type='num', start_value=0, start_color='FF0000',\n",
    "        mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "        end_type='num', end_value=100, end_color='00FF00'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # create a new workbook\n",
    "        wb = openpyxl.Workbook()\n",
    "        \n",
    "        # create sheets for each dataset and problem type\n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                sheet_name = f\"{dataset_name} {problem_type.capitalize()}\"[:31]\n",
    "                ws = wb.create_sheet(sheet_name)\n",
    "                \n",
    "                # write the data to the worksheet\n",
    "                for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n",
    "                    for c_idx, value in enumerate(row, 1):\n",
    "                        ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "                \n",
    "                # apply header formatting\n",
    "                for cell in ws[1]:\n",
    "                    cell.fill = header_fill\n",
    "                    cell.font = header_font\n",
    "                    cell.alignment = center_alignment\n",
    "                \n",
    "                # find accuracy and correct columns\n",
    "                for col_idx, col in enumerate(ws.iter_cols(), 1):\n",
    "                    col_name = col[0].value\n",
    "                    \n",
    "                    if col_name and 'Accuracy (%)' in col_name:\n",
    "                        # apply color scale to accuracy columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            color_scale_rule\n",
    "                        )\n",
    "                    \n",
    "                    elif col_name and 'Correct' in col_name:\n",
    "                        # apply green/red to correctness columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['TRUE'], fill=green_fill)\n",
    "                        )\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['FALSE'], fill=red_fill)\n",
    "                        )\n",
    "                \n",
    "                # auto-size columns\n",
    "                for column in ws.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(str(cell.value))\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = (max_length + 2)\n",
    "                    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # create summary sheet\n",
    "        ws_summary = wb.create_sheet(\"Model Performance Summary\")\n",
    "        \n",
    "        # prepare summary data\n",
    "        summary_data = []\n",
    "        models_list = ['Random Forest', 'Logistic Regression', 'XGBoost']\n",
    "        \n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                for model in models_list:\n",
    "                    # calculate average accuracy\n",
    "                    acc_col = f\"{model} Accuracy (%)\"\n",
    "                    if acc_col in df.columns:\n",
    "                        avg_accuracy = df[acc_col].mean()\n",
    "                        \n",
    "                        # calculate error rate (false predictions percentage)\n",
    "                        correct_col = f\"{model} Correct\"\n",
    "                        if correct_col in df.columns:\n",
    "                            total_predictions = len(df[correct_col])\n",
    "                            true_predictions = len(df[df[correct_col] == True])\n",
    "                            accuracy_rate = (true_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "                            \n",
    "                            summary_data.append({\n",
    "                                'Dataset': dataset_name,\n",
    "                                'Problem Type': problem_type.capitalize(),\n",
    "                                'Model': model,\n",
    "                                'Average Accuracy (%)': round(avg_accuracy, 1),\n",
    "                                'Accuracy Rate (%)': round(accuracy_rate, 1),\n",
    "                                'Total Predictions': total_predictions\n",
    "                            })\n",
    "        \n",
    "        # create summary DataFrame\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # write summary to Excel\n",
    "        for r_idx, row in enumerate(dataframe_to_rows(summary_df, index=False, header=True), 1):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                ws_summary.cell(row=r_idx, column=c_idx, value=value)\n",
    "        \n",
    "        # format summary sheet\n",
    "        for cell in ws_summary[1]:\n",
    "            cell.fill = summary_header_fill\n",
    "            cell.font = header_font\n",
    "            cell.alignment = center_alignment\n",
    "        \n",
    "        # apply conditional formatting to accuracy and error rate\n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"D2:D{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000',\n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"E2:E{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000', \n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00', \n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Auto-size columns\n",
    "        for column in ws_summary.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            ws_summary.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # Add charts to summary sheet\n",
    "        chart1 = BarChart()\n",
    "        chart1.title = \"Average Accuracy by Model\"\n",
    "        chart1.y_axis.title = \"Accuracy (%)\"\n",
    "        chart1.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=4, min_row=1, max_row=ws_summary.max_row, max_col=4)\n",
    "        cats = Reference(ws_summary, min_col=3, min_row=2, max_row=ws_summary.max_row)\n",
    "        chart1.add_data(data, titles_from_data=True)\n",
    "        chart1.set_categories(cats)\n",
    "        ws_summary.add_chart(chart1, \"G2\")\n",
    "        \n",
    "        chart2 = BarChart()\n",
    "        chart2.title = \"Error Rate by Model\"\n",
    "        chart2.y_axis.title = \"Error Rate (%)\"\n",
    "        chart2.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=5, min_row=1, max_row=ws_summary.max_row, max_col=5)\n",
    "        chart2.add_data(data, titles_from_data=True)\n",
    "        chart2.set_categories(cats)\n",
    "        ws_summary.add_chart(chart2, \"G20\")\n",
    "        \n",
    "        # Remove default sheet if it exists\n",
    "        if 'Sheet' in wb.sheetnames:\n",
    "            wb.remove(wb['Sheet'])\n",
    "        \n",
    "        # Save the workbook\n",
    "        wb.save(output_file)\n",
    "        print(f\"Successfully saved report to: {os.path.abspath(output_file)}\")\n",
    "        return output_file\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Excel report: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# 7. generate the report\n",
    "report_file = create_excel_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc1e99d-e40e-4b3e-a8dd-95ae98000cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37dd405-5ad3-4e24-b7ef-89aa4f0c1648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Excel report: additional_report_v3.xlsx\n",
      "Successfully saved report to: /Users/dingyangzuo/additional_report_v3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from difflib import SequenceMatcher\n",
    "from openpyxl.styles import PatternFill, Font, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule, ColorScaleRule\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.chart import BarChart\n",
    "from openpyxl.chart.reference import Reference\n",
    "\n",
    "\n",
    "# 1. load saved models and preprocessing objects\n",
    "model_dir = 'saved_models_additional_v3'\n",
    "models = {\n",
    "    'illness': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_illness.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_illness.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_injury.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_injury.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# load vectorizers and encoders\n",
    "vectorizers = {\n",
    "    'illness': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_illness.pkl')),\n",
    "    'injury': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_injury.pkl'))\n",
    "}\n",
    "\n",
    "label_encoders = {\n",
    "    'illness': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_illness_label_encoder.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_injury_label_encoder.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. load and prepare data with column name standardization\n",
    "def load_and_prepare_data(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # standardize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    illness_columns = ['type_of_illness', 'illness_severity']\n",
    "    injury_columns = ['injury_location', 'injury_type', 'injury_severity']\n",
    "    df['illness_text'] = df[illness_columns].fillna('').agg(' '.join, axis=1)\n",
    "    df['injury_text'] = df[injury_columns].fillna('').agg(' '.join, axis=1)\n",
    "    df['injury_information'] = df['injury_text'].fillna(\"No Injury\")\n",
    "    df['illness_information'] = df['illness_text'].fillna(\"No Illness\")\n",
    "    \n",
    "    # ensure required columns exist\n",
    "    if 'user_id' not in df.columns:\n",
    "        df['user_id'] = np.arange(1, len(df)+1)\n",
    "    \n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # convert date to string if it's datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "        df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "test_df = load_and_prepare_data(\"cleaned_test_data_v3.xlsx\")\n",
    "realuse_df = load_and_prepare_data(\"cleaned_realuse_data_v3.xlsx\")\n",
    "\n",
    "# 3. enhanced prediction function\n",
    "def predict_with_models(text, problem_type, actual):\n",
    "    predictions = {}\n",
    "    if text in [\"No Illness\", \"No Injury\"]:\n",
    "        return {model: (\"No Prediction\", 0) for model in models[problem_type].keys()}\n",
    "    \n",
    "    vectorized = vectorizers[problem_type].transform([text])\n",
    "    \n",
    "    for model_name, model in models[problem_type].items():\n",
    "        pred = model.predict(vectorized)[0]\n",
    "        \n",
    "        if model_name in ['Logistic Regression', 'XGBoost']:\n",
    "            pred = label_encoders[problem_type][model_name].inverse_transform([pred])[0]\n",
    "        \n",
    "        similarity = SequenceMatcher(None, str(actual), str(pred)).ratio() * 100\n",
    "        predictions[model_name] = (pred, similarity)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 4. process dataset to create flattened results - only for rows with illness or injury\n",
    "def process_dataset(df):\n",
    "    illness_results = []\n",
    "    injury_results = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        user_id = str(row['user_id'])\n",
    "        date = str(row['date'])\n",
    "        \n",
    "        # process illness if present\n",
    "        if row['illed'] == 1 and row['illness_information'] != \"No Illness\":\n",
    "            illness_actual = row['illness_information']\n",
    "            illness_preds = predict_with_models(illness_actual, 'illness', illness_actual)\n",
    "            \n",
    "            illness_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': illness_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in illness_preds.items():\n",
    "                illness_data[f\"{model_name} Predicted\"] = predicted\n",
    "                illness_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                illness_data[f\"{model_name} Correct\"] = illness_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            illness_results.append(illness_data)\n",
    "        \n",
    "        # process injury if present\n",
    "        if row['injured'] == 1 and row['injury_information'] != \"No Injury\":\n",
    "            injury_actual = row['injury_information']\n",
    "            injury_preds = predict_with_models(injury_actual, 'injury', injury_actual)\n",
    "            \n",
    "            injury_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': injury_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in injury_preds.items():\n",
    "                injury_data[f\"{model_name} Predicted\"] = predicted\n",
    "                injury_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                injury_data[f\"{model_name} Correct\"] = injury_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            injury_results.append(injury_data)\n",
    "            \n",
    "    def sort_dataframe(df):\n",
    "        if not df.empty:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.sort_values(['Date', 'User ID'])\n",
    "            df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "        return df\n",
    "    \n",
    "    return {\n",
    "        'illness': sort_dataframe(pd.DataFrame(illness_results)),\n",
    "        'injury': sort_dataframe(pd.DataFrame(injury_results))\n",
    "    }\n",
    "\n",
    "# 5. process both datasets\n",
    "test_results = {\n",
    "    'illness': process_dataset(test_df)['illness'],\n",
    "    'injury': process_dataset(test_df)['injury']\n",
    "}\n",
    "\n",
    "realuse_results = {\n",
    "    'illness': process_dataset(realuse_df)['illness'],\n",
    "    'injury': process_dataset(realuse_df)['injury']\n",
    "}\n",
    "\n",
    "# 6. create Excel report with enhanced formatting\n",
    "def create_excel_report():\n",
    "    output_file = 'additional_report_v3.xlsx'\n",
    "    print(f\"\\nGenerating Excel report: {output_file}\")\n",
    "    \n",
    "    # create styles\n",
    "    green_fill = PatternFill(start_color='00FF00', end_color='00FF00', fill_type='solid')\n",
    "    red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "    header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    header_font = Font(color='FFFFFF', bold=True)\n",
    "    summary_header_fill = PatternFill(start_color='7030A0', end_color='7030A0', fill_type='solid')\n",
    "    center_alignment = Alignment(horizontal='center')\n",
    "    \n",
    "    color_scale_rule = ColorScaleRule(\n",
    "        start_type='num', start_value=0, start_color='FF0000',\n",
    "        mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "        end_type='num', end_value=100, end_color='00FF00'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # create a new workbook\n",
    "        wb = openpyxl.Workbook()\n",
    "        \n",
    "        # create sheets for each dataset and problem type\n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                sheet_name = f\"{dataset_name} {problem_type.capitalize()}\"[:31]\n",
    "                ws = wb.create_sheet(sheet_name)\n",
    "                \n",
    "                # write the data to the worksheet\n",
    "                for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n",
    "                    for c_idx, value in enumerate(row, 1):\n",
    "                        ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "                \n",
    "                # apply header formatting\n",
    "                for cell in ws[1]:\n",
    "                    cell.fill = header_fill\n",
    "                    cell.font = header_font\n",
    "                    cell.alignment = center_alignment\n",
    "                \n",
    "                # find accuracy and correct columns\n",
    "                for col_idx, col in enumerate(ws.iter_cols(), 1):\n",
    "                    col_name = col[0].value\n",
    "                    \n",
    "                    if col_name and 'Accuracy (%)' in col_name:\n",
    "                        # apply color scale to accuracy columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            color_scale_rule\n",
    "                        )\n",
    "                    \n",
    "                    elif col_name and 'Correct' in col_name:\n",
    "                        # apply green/red to correctness columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['TRUE'], fill=green_fill)\n",
    "                        )\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['FALSE'], fill=red_fill)\n",
    "                        )\n",
    "                \n",
    "                # auto-size columns\n",
    "                for column in ws.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(str(cell.value))\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = (max_length + 2)\n",
    "                    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # create summary sheet\n",
    "        ws_summary = wb.create_sheet(\"Model Performance Summary\")\n",
    "        \n",
    "        # prepare summary data\n",
    "        summary_data = []\n",
    "        models_list = ['Random Forest', 'Logistic Regression', 'XGBoost']\n",
    "        \n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                for model in models_list:\n",
    "                    # calculate average accuracy\n",
    "                    acc_col = f\"{model} Accuracy (%)\"\n",
    "                    if acc_col in df.columns:\n",
    "                        avg_accuracy = df[acc_col].mean()\n",
    "                        \n",
    "                        # calculate error rate (false predictions percentage)\n",
    "                        correct_col = f\"{model} Correct\"\n",
    "                        if correct_col in df.columns:\n",
    "                            total_predictions = len(df[correct_col])\n",
    "                            true_predictions = len(df[df[correct_col] == True])\n",
    "                            accuracy_rate = (true_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "                            \n",
    "                            summary_data.append({\n",
    "                                'Dataset': dataset_name,\n",
    "                                'Problem Type': problem_type.capitalize(),\n",
    "                                'Model': model,\n",
    "                                'Average Accuracy (%)': round(avg_accuracy, 1),\n",
    "                                'Accuracy Rate (%)': round(accuracy_rate, 1),\n",
    "                                'Total Predictions': total_predictions\n",
    "                            })\n",
    "        \n",
    "        # create summary DataFrame\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # write summary to Excel\n",
    "        for r_idx, row in enumerate(dataframe_to_rows(summary_df, index=False, header=True), 1):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                ws_summary.cell(row=r_idx, column=c_idx, value=value)\n",
    "        \n",
    "        # format summary sheet\n",
    "        for cell in ws_summary[1]:\n",
    "            cell.fill = summary_header_fill\n",
    "            cell.font = header_font\n",
    "            cell.alignment = center_alignment\n",
    "        \n",
    "        # apply conditional formatting to accuracy and error rate\n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"D2:D{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000',\n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"E2:E{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000', \n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00', \n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Auto-size columns\n",
    "        for column in ws_summary.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            ws_summary.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # Add charts to summary sheet\n",
    "        chart1 = BarChart()\n",
    "        chart1.title = \"Average Accuracy by Model\"\n",
    "        chart1.y_axis.title = \"Accuracy (%)\"\n",
    "        chart1.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=4, min_row=1, max_row=ws_summary.max_row, max_col=4)\n",
    "        cats = Reference(ws_summary, min_col=3, min_row=2, max_row=ws_summary.max_row)\n",
    "        chart1.add_data(data, titles_from_data=True)\n",
    "        chart1.set_categories(cats)\n",
    "        ws_summary.add_chart(chart1, \"G2\")\n",
    "        \n",
    "        chart2 = BarChart()\n",
    "        chart2.title = \"Error Rate by Model\"\n",
    "        chart2.y_axis.title = \"Error Rate (%)\"\n",
    "        chart2.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=5, min_row=1, max_row=ws_summary.max_row, max_col=5)\n",
    "        chart2.add_data(data, titles_from_data=True)\n",
    "        chart2.set_categories(cats)\n",
    "        ws_summary.add_chart(chart2, \"G20\")\n",
    "        \n",
    "        # Remove default sheet if it exists\n",
    "        if 'Sheet' in wb.sheetnames:\n",
    "            wb.remove(wb['Sheet'])\n",
    "        \n",
    "        # Save the workbook\n",
    "        wb.save(output_file)\n",
    "        print(f\"Successfully saved report to: {os.path.abspath(output_file)}\")\n",
    "        return output_file\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Excel report: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# 7. generate the report\n",
    "report_file = create_excel_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d89db-3f2f-4909-8a45-9f7e3173ede5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f45783-2684-4490-a8f4-544b1daf32a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Excel report: additional_report_v3_no_severity.xlsx\n",
      "Successfully saved report to: /Users/dingyangzuo/additional_report_v3_no_severity.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from difflib import SequenceMatcher\n",
    "from openpyxl.styles import PatternFill, Font, Alignment\n",
    "from openpyxl.formatting.rule import CellIsRule, ColorScaleRule\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.chart import BarChart\n",
    "from openpyxl.chart.reference import Reference\n",
    "\n",
    "\n",
    "# 1. load saved models and preprocessing objects\n",
    "model_dir = 'saved_models_additional_v2_no_severity'\n",
    "models = {\n",
    "    'illness': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_illness.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_illness.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Random Forest': joblib.load(os.path.join(model_dir, 'rf_model_injury.pkl')),\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'log_reg_model_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_model_injury.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# load vectorizers and encoders\n",
    "vectorizers = {\n",
    "    'illness': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_illness.pkl')),\n",
    "    'injury': joblib.load(os.path.join(model_dir, 'tfidf_vectorizer_injury.pkl'))\n",
    "}\n",
    "\n",
    "label_encoders = {\n",
    "    'illness': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_illness.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_illness_label_encoder.pkl'))\n",
    "    },\n",
    "    'injury': {\n",
    "        'Logistic Regression': joblib.load(os.path.join(model_dir, 'label_encoder_log_reg_injury.pkl')),\n",
    "        'XGBoost': joblib.load(os.path.join(model_dir, 'xgb_injury_label_encoder.pkl'))\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. load and prepare data with column name standardization\n",
    "def load_and_prepare_data(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # standardize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    illness_columns = ['type_of_illness', 'illness_severity']\n",
    "    injury_columns = ['injury_location', 'injury_type']\n",
    "    df['illness_text'] = df[illness_columns].fillna('').agg(' '.join, axis=1)\n",
    "    df['injury_text'] = df[injury_columns].fillna('').agg(' '.join, axis=1)\n",
    "    df['injury_information'] = df['injury_text'].fillna(\"No Injury\")\n",
    "    df['illness_information'] = df['illness_text'].fillna(\"No Illness\")\n",
    "    \n",
    "    # ensure required columns exist\n",
    "    if 'user_id' not in df.columns:\n",
    "        df['user_id'] = np.arange(1, len(df)+1)\n",
    "    \n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # convert date to string if it's datetime\n",
    "    if pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "        df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "test_df = load_and_prepare_data(\"cleaned_test_data_v3.xlsx\")\n",
    "realuse_df = load_and_prepare_data(\"cleaned_realuse_data_v3.xlsx\")\n",
    "\n",
    "# 3. enhanced prediction function\n",
    "def predict_with_models(text, problem_type, actual):\n",
    "    predictions = {}\n",
    "    if text in [\"No Illness\", \"No Injury\"]:\n",
    "        return {model: (\"No Prediction\", 0) for model in models[problem_type].keys()}\n",
    "    \n",
    "    vectorized = vectorizers[problem_type].transform([text])\n",
    "    \n",
    "    for model_name, model in models[problem_type].items():\n",
    "        pred = model.predict(vectorized)[0]\n",
    "        \n",
    "        if model_name in ['Logistic Regression', 'XGBoost']:\n",
    "            pred = label_encoders[problem_type][model_name].inverse_transform([pred])[0]\n",
    "        \n",
    "        similarity = SequenceMatcher(None, str(actual), str(pred)).ratio() * 100\n",
    "        predictions[model_name] = (pred, similarity)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 4. process dataset to create flattened results - only for rows with illness or injury\n",
    "def process_dataset(df):\n",
    "    illness_results = []\n",
    "    injury_results = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        user_id = str(row['user_id'])\n",
    "        date = str(row['date'])\n",
    "        \n",
    "        # process illness if present\n",
    "        if row['illed'] == 1 and row['illness_information'] != \"No Illness\":\n",
    "            illness_actual = row['illness_information']\n",
    "            illness_preds = predict_with_models(illness_actual, 'illness', illness_actual)\n",
    "            \n",
    "            illness_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': illness_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in illness_preds.items():\n",
    "                illness_data[f\"{model_name} Predicted\"] = predicted\n",
    "                illness_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                illness_data[f\"{model_name} Correct\"] = illness_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            illness_results.append(illness_data)\n",
    "        \n",
    "        # process injury if present\n",
    "        if row['injured'] == 1 and row['injury_information'] != \"No Injury\":\n",
    "            injury_actual = row['injury_information']\n",
    "            injury_preds = predict_with_models(injury_actual, 'injury', injury_actual)\n",
    "            \n",
    "            injury_data = {\n",
    "                'User ID': user_id,\n",
    "                'Date': date,\n",
    "                'Actual': injury_actual\n",
    "            }\n",
    "            \n",
    "            for model_name, (predicted, similarity) in injury_preds.items():\n",
    "                injury_data[f\"{model_name} Predicted\"] = predicted\n",
    "                injury_data[f\"{model_name} Accuracy (%)\"] = round(similarity, 1)\n",
    "                injury_data[f\"{model_name} Correct\"] = injury_actual == predicted if predicted != \"No Prediction\" else False\n",
    "            \n",
    "            injury_results.append(injury_data)\n",
    "            \n",
    "    def sort_dataframe(df):\n",
    "        if not df.empty:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.sort_values(['Date', 'User ID'])\n",
    "            df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "        return df\n",
    "    \n",
    "    return {\n",
    "        'illness': sort_dataframe(pd.DataFrame(illness_results)),\n",
    "        'injury': sort_dataframe(pd.DataFrame(injury_results))\n",
    "    }\n",
    "\n",
    "# 5. process both datasets\n",
    "test_results = {\n",
    "    'illness': process_dataset(test_df)['illness'],\n",
    "    'injury': process_dataset(test_df)['injury']\n",
    "}\n",
    "\n",
    "realuse_results = {\n",
    "    'illness': process_dataset(realuse_df)['illness'],\n",
    "    'injury': process_dataset(realuse_df)['injury']\n",
    "}\n",
    "\n",
    "# 6. create Excel report with enhanced formatting\n",
    "def create_excel_report():\n",
    "    output_file = 'additional_report_v3_no_severity.xlsx'\n",
    "    print(f\"\\nGenerating Excel report: {output_file}\")\n",
    "    \n",
    "    # create styles\n",
    "    green_fill = PatternFill(start_color='00FF00', end_color='00FF00', fill_type='solid')\n",
    "    red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "    header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    header_font = Font(color='FFFFFF', bold=True)\n",
    "    summary_header_fill = PatternFill(start_color='7030A0', end_color='7030A0', fill_type='solid')\n",
    "    center_alignment = Alignment(horizontal='center')\n",
    "    \n",
    "    color_scale_rule = ColorScaleRule(\n",
    "        start_type='num', start_value=0, start_color='FF0000',\n",
    "        mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "        end_type='num', end_value=100, end_color='00FF00'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # create a new workbook\n",
    "        wb = openpyxl.Workbook()\n",
    "        \n",
    "        # create sheets for each dataset and problem type\n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                sheet_name = f\"{dataset_name} {problem_type.capitalize()}\"[:31]\n",
    "                ws = wb.create_sheet(sheet_name)\n",
    "                \n",
    "                # write the data to the worksheet\n",
    "                for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True), 1):\n",
    "                    for c_idx, value in enumerate(row, 1):\n",
    "                        ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "                \n",
    "                # apply header formatting\n",
    "                for cell in ws[1]:\n",
    "                    cell.fill = header_fill\n",
    "                    cell.font = header_font\n",
    "                    cell.alignment = center_alignment\n",
    "                \n",
    "                # find accuracy and correct columns\n",
    "                for col_idx, col in enumerate(ws.iter_cols(), 1):\n",
    "                    col_name = col[0].value\n",
    "                    \n",
    "                    if col_name and 'Accuracy (%)' in col_name:\n",
    "                        # apply color scale to accuracy columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            color_scale_rule\n",
    "                        )\n",
    "                    \n",
    "                    elif col_name and 'Correct' in col_name:\n",
    "                        # apply green/red to correctness columns\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['TRUE'], fill=green_fill)\n",
    "                        )\n",
    "                        ws.conditional_formatting.add(\n",
    "                            f\"{openpyxl.utils.get_column_letter(col_idx)}2:{openpyxl.utils.get_column_letter(col_idx)}{ws.max_row}\",\n",
    "                            CellIsRule(operator='equal', formula=['FALSE'], fill=red_fill)\n",
    "                        )\n",
    "                \n",
    "                # auto-size columns\n",
    "                for column in ws.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(str(cell.value))\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = (max_length + 2)\n",
    "                    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # create summary sheet\n",
    "        ws_summary = wb.create_sheet(\"Model Performance Summary\")\n",
    "        \n",
    "        # prepare summary data\n",
    "        summary_data = []\n",
    "        models_list = ['Random Forest', 'Logistic Regression', 'XGBoost']\n",
    "        \n",
    "        for dataset_name, results in [('Test Data', test_results), ('Real-use Data', realuse_results)]:\n",
    "            for problem_type in ['illness', 'injury']:\n",
    "                df = results[problem_type]\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                \n",
    "                for model in models_list:\n",
    "                    # calculate average accuracy\n",
    "                    acc_col = f\"{model} Accuracy (%)\"\n",
    "                    if acc_col in df.columns:\n",
    "                        avg_accuracy = df[acc_col].mean()\n",
    "                        \n",
    "                        # calculate error rate (false predictions percentage)\n",
    "                        correct_col = f\"{model} Correct\"\n",
    "                        if correct_col in df.columns:\n",
    "                            total_predictions = len(df[correct_col])\n",
    "                            true_predictions = len(df[df[correct_col] == True])\n",
    "                            accuracy_rate = (true_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "                            \n",
    "                            summary_data.append({\n",
    "                                'Dataset': dataset_name,\n",
    "                                'Problem Type': problem_type.capitalize(),\n",
    "                                'Model': model,\n",
    "                                'Average Accuracy (%)': round(avg_accuracy, 1),\n",
    "                                'Accuracy Rate (%)': round(accuracy_rate, 1),\n",
    "                                'Total Predictions': total_predictions\n",
    "                            })\n",
    "        \n",
    "        # create summary DataFrame\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # write summary to Excel\n",
    "        for r_idx, row in enumerate(dataframe_to_rows(summary_df, index=False, header=True), 1):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                ws_summary.cell(row=r_idx, column=c_idx, value=value)\n",
    "        \n",
    "        # format summary sheet\n",
    "        for cell in ws_summary[1]:\n",
    "            cell.fill = summary_header_fill\n",
    "            cell.font = header_font\n",
    "            cell.alignment = center_alignment\n",
    "        \n",
    "        # apply conditional formatting to accuracy and error rate\n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"D2:D{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000',\n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00',\n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        ws_summary.conditional_formatting.add(\n",
    "            f\"E2:E{ws_summary.max_row}\",\n",
    "            ColorScaleRule(\n",
    "                start_type='num', start_value=0, start_color='FF0000', \n",
    "                mid_type='num', mid_value=50, mid_color='FFFF00', \n",
    "                end_type='num', end_value=100, end_color='00FF00'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Auto-size columns\n",
    "        for column in ws_summary.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2)\n",
    "            ws_summary.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        # Add charts to summary sheet\n",
    "        chart1 = BarChart()\n",
    "        chart1.title = \"Average Accuracy by Model\"\n",
    "        chart1.y_axis.title = \"Accuracy (%)\"\n",
    "        chart1.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=4, min_row=1, max_row=ws_summary.max_row, max_col=4)\n",
    "        cats = Reference(ws_summary, min_col=3, min_row=2, max_row=ws_summary.max_row)\n",
    "        chart1.add_data(data, titles_from_data=True)\n",
    "        chart1.set_categories(cats)\n",
    "        ws_summary.add_chart(chart1, \"G2\")\n",
    "        \n",
    "        chart2 = BarChart()\n",
    "        chart2.title = \"Error Rate by Model\"\n",
    "        chart2.y_axis.title = \"Error Rate (%)\"\n",
    "        chart2.x_axis.title = \"Model\"\n",
    "        \n",
    "        data = Reference(ws_summary, min_col=5, min_row=1, max_row=ws_summary.max_row, max_col=5)\n",
    "        chart2.add_data(data, titles_from_data=True)\n",
    "        chart2.set_categories(cats)\n",
    "        ws_summary.add_chart(chart2, \"G20\")\n",
    "        \n",
    "        # Remove default sheet if it exists\n",
    "        if 'Sheet' in wb.sheetnames:\n",
    "            wb.remove(wb['Sheet'])\n",
    "        \n",
    "        # Save the workbook\n",
    "        wb.save(output_file)\n",
    "        print(f\"Successfully saved report to: {os.path.abspath(output_file)}\")\n",
    "        return output_file\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Excel report: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# 7. generate the report\n",
    "report_file = create_excel_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6627f0b-22d1-4833-bb2d-381fe4eab4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
