{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65b0da-0748-4487-b380-5a02d0276c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================== handling xgb illness label encoder ==================================================\n",
      "loading label encoder for xgb: saved_models/xgb_illness_label_encoder.pkl\n",
      "\n",
      "================================================== handling xgb injury label encoder ==================================================\n",
      "loading label encoder for xgb: saved_models/xgb_injury_label_encoder.pkl\n",
      "Loading saved model from: saved_models/xgb_model_injury.pkl\n",
      "Loading saved model from: saved_models/enhanced_xgb_model_injury.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "\n",
    "model_dir = 'saved_models'\n",
    "new_xgb_injury_model_path = os.path.join(model_dir, 'enhanced_xgb_model_injury.pkl')\n",
    "xgb_illness_label_encoder_path = os.path.join(model_dir, 'xgb_illness_label_encoder.pkl')\n",
    "xgb_injury_label_encoder_path = os.path.join(model_dir, 'xgb_injury_label_encoder.pkl')\n",
    "\n",
    "\n",
    "# Function to load the existing model if it exists\n",
    "def load_existing_model(model_path):\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading saved model from: {model_path}\")\n",
    "        model = joblib.load(model_path)\n",
    "        return model\n",
    "    else:\n",
    "        print(f\"No existing model found at: {model_path}. Starting fresh.\")\n",
    "        return None\n",
    "\n",
    "def save_checkpoint(model, checkpoint_path, iteration):\n",
    "    joblib.dump(model, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at iteration {iteration} to {checkpoint_path}\")\n",
    "\n",
    "# Function to continue training an existing model\n",
    "def train_model_from_existing_model(model, X_train, y_train, model_path, checkpoint_interval=5, max_rounds=55):\n",
    "    checkpoint_path = os.path.join(model_dir, 'xgb_injury_model_checkpoint.pkl')\n",
    "    checkpoint_file = os.path.join(model_dir, 'xgb_injury_model_checkpoint_rounds.txt')\n",
    "    start_iteration = 0\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading saved model from: {model_path}\")\n",
    "        model = joblib.load(model_path)\n",
    "        if hasattr(model, 'best_iteration'):\n",
    "            start_iteration = model.best_iteration\n",
    "    elif os.path.exists(checkpoint_path):\n",
    "        print(f\"Resuming training from checkpoint: {checkpoint_path}\")\n",
    "        model = joblib.load(checkpoint_path)\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            checkpoint_rounds = int(f.read().strip())\n",
    "            print(f\"Resuming from saved round: {checkpoint_rounds}\")\n",
    "            start_iteration = checkpoint_rounds\n",
    "\n",
    "    eval_set = [(X_train, y_train)]\n",
    "\n",
    "    # Train the model, starting from the last best_iteration\n",
    "    for i in range(start_iteration, max_rounds):\n",
    "        model.fit(X_train, y_train, eval_set=eval_set, verbose=True, xgb_model=model.get_booster() if i > 0 else None)\n",
    "\n",
    "        # Save checkpoint after each 5 rounds\n",
    "        if (i + 1) % checkpoint_interval == 0:\n",
    "            save_checkpoint(model, checkpoint_path, i + 1)\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                f.write(str(i + 1))\n",
    "\n",
    "        # Save the round checkpoint number\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            f.write(str(i + 1))\n",
    "\n",
    "    # Save the final model after training\n",
    "    joblib.dump(model, new_xgb_injury_model_path)\n",
    "\n",
    "    # Clean up the checkpoint file after final save\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        os.remove(checkpoint_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load training and testing data\n",
    "train_df = pd.read_excel(\"cleaned_training_data_v3.xlsx\")\n",
    "test_df = pd.read_excel(\"cleaned_test_data_v3.xlsx\") \n",
    "\n",
    "# Define numeric features\n",
    "numeric_features = ['Gender_m2f1', 'Menstruation_y1n0', 'Mood state', 'Energy levels',\n",
    "                    'Muscle readiness', 'Academic Pressure', 'Diet Yesterday', 'Sleep quality',\n",
    "                    'Sleep duration', 'sleep_score', 'total_training_load', 'total_training_duration',\n",
    "                    'weekly_training_load', 'weekly_training_duration', 'ACWR', 'RTT', 'illed', 'injured']\n",
    "\n",
    "# Separate numeric features from the rest\n",
    "X_train = train_df[numeric_features]\n",
    "X_test = test_df[numeric_features]\n",
    "\n",
    "# Combine text columns for illness and injury separately\n",
    "illness_columns = ['Type of illness', 'Illness severity']\n",
    "injury_columns = ['Injury location', 'Injury type', 'Injury surface', 'Surface condition', 'Injury tissue type', 'Injury severity']\n",
    "\n",
    "# Fill missing values and concatenate the text columns\n",
    "train_df['illness_text'] = train_df[illness_columns].fillna('').agg(' '.join, axis=1)\n",
    "train_df['injury_text'] = train_df[injury_columns].fillna('').agg(' '.join, axis=1)\n",
    "test_df['illness_text'] = test_df[illness_columns].fillna('').agg(' '.join, axis=1)\n",
    "test_df['injury_text'] = test_df[injury_columns].fillna('').agg(' '.join, axis=1)\n",
    "train_df['injury_information'] = train_df['injury_information'].fillna(\"No Injury\")\n",
    "train_df['illness_information'] = train_df['illness_information'].fillna(\"No Illness\")\n",
    "test_df['injury_information'] = test_df['injury_information'].fillna(\"No Injury\")\n",
    "test_df['illness_information'] = test_df['illness_information'].fillna(\"No Illness\")\n",
    "\n",
    "# Vectorize the text data using TfidfVectorizer\n",
    "tfidf_vectorizer_illness = TfidfVectorizer(max_features=500)\n",
    "tfidf_vectorizer_injury = TfidfVectorizer(max_features=500)\n",
    "\n",
    "# Fit the vectorizers on training data and transform the test data\n",
    "X_illness_train = tfidf_vectorizer_illness.fit_transform(train_df['illness_information'])\n",
    "X_injury_train = tfidf_vectorizer_injury.fit_transform(train_df['injury_information'])\n",
    "X_illness_test = tfidf_vectorizer_illness.transform(test_df['illness_information'])\n",
    "X_injury_test = tfidf_vectorizer_injury.transform(test_df['injury_information'])\n",
    "\n",
    "# Save the vectorizers for later use\n",
    "joblib.dump(tfidf_vectorizer_illness, os.path.join(model_dir, 'tfidf_vectorizer_illness.pkl'))\n",
    "joblib.dump(tfidf_vectorizer_injury, os.path.join(model_dir, 'tfidf_vectorizer_injury.pkl'))\n",
    "\n",
    "# function to encode the target variable\n",
    "def handle_label_encoder(y_train, encoder_path):\n",
    "    if os.path.exists(encoder_path):\n",
    "        print(f\"loading label encoder for xgb: {encoder_path}\")\n",
    "        encoder = joblib.load(encoder_path)\n",
    "        y_encoded = encoder.transform(y_train) \n",
    "    else:\n",
    "        print(f\"creating new label encoder for xgb: {encoder_path}\")\n",
    "        encoder = LabelEncoder()\n",
    "        y_encoded = encoder.fit_transform(y_train)\n",
    "        joblib.dump(encoder, encoder_path)\n",
    "    return y_encoded, encoder\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \" handling xgb illness label encoder \" + \"=\"*50)\n",
    "y_illness_encoded, illness_encoder = handle_label_encoder(train_df['illness_information'], xgb_illness_label_encoder_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \" handling xgb injury label encoder \" + \"=\"*50)\n",
    "y_injury_encoded, injury_encoder = handle_label_encoder(train_df['injury_information'], xgb_injury_label_encoder_path)\n",
    "\n",
    "# Resample the training data using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_resampled_illness, y_resampled_illness = ros.fit_resample(X_illness_train, y_illness_encoded)\n",
    "X_resampled_injury, y_resampled_injury = ros.fit_resample(X_injury_train, y_injury_encoded)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train_illness, X_test_illness, y_train_illness, y_test_illness = train_test_split(X_resampled_illness, y_resampled_illness, test_size=0.2, random_state=42)\n",
    "X_train_injury, X_test_injury, y_train_injury, y_test_injury = train_test_split(X_resampled_injury, y_resampled_injury, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare model paths\n",
    "xgb_injury_model_path = os.path.join(model_dir, 'xgb_model_injury.pkl')\n",
    "\n",
    "# Check if the model already exists, if not, create a new one\n",
    "best_xgb_model_injury = load_existing_model(xgb_injury_model_path)\n",
    "\n",
    "# Set up XGBoost parameters\n",
    "positive_class_count_injury = sum(y_train_injury == 1)\n",
    "negative_class_count_injury = sum(y_train_injury == 0)\n",
    "scale_pos_weight_injury = negative_class_count_injury / positive_class_count_injury if positive_class_count_injury > 0 else 1\n",
    "\n",
    "xgb_param_injury = {\n",
    "    'n_estimators': 55,\n",
    "    'learning_rate': 0.05,  # Reduced learning rate\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'enable_categorical': True,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cpu',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'scale_pos_weight': scale_pos_weight_injury\n",
    "}\n",
    "\n",
    "# Create the XGBoost model if it doesn't exist\n",
    "if best_xgb_model_injury is None:\n",
    "    best_xgb_model_injury = xgb.XGBClassifier(random_state=42, **xgb_param_injury)\n",
    "    best_xgb_model_injury.classes_ = injury_encoder.classes_\n",
    "\n",
    "\n",
    "# Continue training the model for additional rounds\n",
    "best_xgb_model_injury = train_model_from_existing_model(\n",
    "    model=best_xgb_model_injury,\n",
    "    X_train=X_train_injury,\n",
    "    y_train=y_train_injury,  # Ensure the target labels are properly encoded\n",
    "    model_path=new_xgb_injury_model_path,\n",
    "    checkpoint_interval=5, \n",
    "    max_rounds=55  \n",
    ")\n",
    "\n",
    "# Optionally, save final model after training\n",
    "joblib.dump(best_xgb_model_injury, new_xgb_injury_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d246b-bd96-4afe-99a8-b8f61b6b012d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
